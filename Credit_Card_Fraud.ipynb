{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "257e2e0b-1d77-4512-b708-6aa3b4a1310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5c15d6-97dd-4932-bcfb-ca610be32424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (ensure the CSV file is in your working directory)\n",
    "data = pd.read_csv(\"data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de9741e-1169-478e-b88f-9803ee994241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8876609-fff2-4e4c-865b-c5a53a2e510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration\n",
    "\n",
    "# Set a consistent style and customize rcParams for a polished look\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "plt.rcParams[\"axes.labelsize\"] = 14\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 12\n",
    "plt.rcParams[\"axes.titlesize\"] = 16\n",
    "plt.rcParams[\"axes.titleweight\"] = \"bold\"\n",
    "\n",
    "# Create a grid layout: 2 rows x 3 columns (we have 5 plots, so one subplot will be removed)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot 1: Distribution of 'Amount'\n",
    "sns.histplot(data['Amount'], bins=50, kde=True, color='skyblue', ax=axes[0])\n",
    "axes[0].set_title(\"Distribution of Transaction Amount\")\n",
    "axes[0].set_xlabel(\"Amount\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Plot 2: Distribution of 'Time'\n",
    "sns.histplot(data['Time'], bins=50, kde=True, color='salmon', ax=axes[1])\n",
    "axes[1].set_title(\"Distribution of Transaction Time\")\n",
    "axes[1].set_xlabel(\"Time (seconds from first transaction)\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Plot 3: Class Distribution (Legitimate vs. Fraudulent)\n",
    "sns.countplot(x='Class', data=data, palette='viridis', ax=axes[2])\n",
    "axes[2].set_title(\"Transaction Class Distribution\")\n",
    "axes[2].set_xlabel(\"Class (0: Legitimate, 1: Fraud)\")\n",
    "axes[2].set_ylabel(\"Count\")\n",
    "\n",
    "# Plot 4: Boxplot of 'Amount'\n",
    "sns.boxplot(x=data['Amount'], color='lightgreen', ax=axes[3])\n",
    "axes[3].set_title(\"Boxplot of Transaction Amount\")\n",
    "axes[3].set_xlabel(\"Amount\")\n",
    "\n",
    "# Plot 5: Boxplot of 'Time'\n",
    "sns.boxplot(x=data['Time'], color='lightcoral', ax=axes[4])\n",
    "axes[4].set_title(\"Boxplot of Transaction Time\")\n",
    "axes[4].set_xlabel(\"Time (seconds)\")\n",
    "\n",
    "# Remove the unused subplot (if any)\n",
    "if len(axes) > 5:\n",
    "    fig.delaxes(axes[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e4a6b-b46f-4160-af44-04194acb55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning and Feature Engineering\n",
    "\n",
    "# Scale the 'Amount' and 'Time' features using RobustScaler (since PCA features are already scaled)\n",
    "rob_scaler = RobustScaler()\n",
    "data['Amount_scaled'] = rob_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data['Time_scaled'] = rob_scaler.fit_transform(data['Time'].values.reshape(-1,1))\n",
    "\n",
    "# Display the first few rows to verify new features\n",
    "print(\"\\nFirst few rows with new features:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d7dfd3-4408-424c-987c-eface8d59679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "\n",
    "# Prepare data\n",
    "features = [col for col in data.columns if col not in ['Class']]\n",
    "X = data[features]\n",
    "y = data['Class']\n",
    "\n",
    "# Train-Test Split with stratification to preserve class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6e6aca-7c64-4965-b1ba-bb3a1e3fd084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# Class-weigth balanced to handle class imbalance\n",
    "log_reg = LogisticRegression(\n",
    "    class_weight='balanced', \n",
    "    max_iter=10000, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class (fraud)\n",
    "y_scores_log = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Convert probabilities to binary predictions (threshold = 0.5)\n",
    "y_pred_log = (y_scores_log >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "log_ap_score = average_precision_score(y_test, y_scores_log)\n",
    "print(\"Logistic Regression AUPRC:\", log_ap_score)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix (Logistic Regression):\")\n",
    "print(confusion_matrix(y_test, y_pred_log))\n",
    "print(\"Classification Report (Logistic Regression):\")\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4952c9a-d0b4-45ca-87b2-e9e637fe7fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "# Class_weight balanced to handle class imbalance\n",
    "svm_clf = SVC(\n",
    "    kernel='rbf',\n",
    "    class_weight='balanced',\n",
    "    probability=True,  # to get predict_proba\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_scores_svm = svm_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_svm = (y_scores_svm >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "svm_ap_score = average_precision_score(y_test, y_scores_svm)\n",
    "print(\"SVM AUPRC:\", svm_ap_score)\n",
    "\n",
    "# Confusion Matrix & Classification Report\n",
    "print(\"Confusion Matrix (SVM):\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"Classification Report (SVM):\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9dd408-fd5e-4f81-98a1-3f387f562ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "# Class_weight balanced to handle class imbalance\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_scores_rf = rf_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_rf = (y_scores_rf >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "rf_ap_score = average_precision_score(y_test, y_scores_rf)\n",
    "print(\"Random Forest AUPRC:\", rf_ap_score)\n",
    "\n",
    "# Confusion Matrix & Classification Report\n",
    "print(\"Confusion Matrix (Random Forest):\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Classification Report (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62576e-91ff-42da-b5e5-ed70ab1a24f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning Models\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Pipeline for Logistic Regression\n",
    "log_pipe = Pipeline([\n",
    "    ('clf', LogisticRegression(class_weight='balanced', solver='liblinear', max_iter=1000))\n",
    "])\n",
    "\n",
    "# Parameter grid\n",
    "param_grid_log = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l1', 'l2']  # 'l1' requires solver='liblinear' or 'saga'\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "log_grid = GridSearchCV(\n",
    "    estimator=log_pipe,\n",
    "    param_grid=param_grid_log,\n",
    "    scoring='average_precision',  # optimizes AUPRC\n",
    "    cv=cv,\n",
    "    n_jobs=-1,  # use all available CPU cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "log_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and its performance\n",
    "print(\"Best Params for Logistic Regression:\", log_grid.best_params_)\n",
    "print(\"Best Average Precision (CV) for Logistic Regression:\", log_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e2d9a5-07b4-4c7c-aeb2-a227d9e0fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for SVM\n",
    "svm_pipe = Pipeline([\n",
    "    ('clf', SVC(class_weight='balanced', probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid\n",
    "param_grid_svm = {\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__gamma': [0.01, 0.001],\n",
    "    'clf__kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "svm_grid = GridSearchCV(\n",
    "    estimator=svm_pipe,\n",
    "    param_grid=param_grid_svm,\n",
    "    scoring='average_precision',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and its performance\n",
    "print(\"Best Params for SVM:\", svm_grid.best_params_)\n",
    "print(\"Best Average Precision (CV) for SVM:\", svm_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94bf4f2-ac00-4a93-b525-a98054c98868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid_rf,\n",
    "    scoring='average_precision',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator and its performance\n",
    "print(\"Best Params for Random Forest:\", rf_grid.best_params_)\n",
    "print(\"Best Average Precision (CV) for Random Forest:\", rf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1bd220-f940-4ba1-a61d-d9f987d549f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best models\n",
    "best_log_model = log_grid.best_estimator_\n",
    "best_svm_model = svm_grid.best_estimator_\n",
    "best_rf_model = rf_grid.best_estimator_\n",
    "\n",
    "# Evaluate each on the test set\n",
    "models = {\n",
    "    \"Logistic Regression\": best_log_model,\n",
    "    \"SVM\": best_svm_model,\n",
    "    \"Random Forest\": best_rf_model\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # For classifiers with predict_proba:\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_scores = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        # Some models (like SVC with probability=False) only have decision_function\n",
    "        y_scores = model.decision_function(X_test)\n",
    "    \n",
    "    # Average Precision on test set\n",
    "    ap_test = average_precision_score(y_test, y_scores)\n",
    "    \n",
    "    # Convert probabilities to binary predictions at threshold=0.5\n",
    "    y_pred = (y_scores >= 0.5).astype(int)\n",
    "    \n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(f\"Test AUPRC: {ap_test:.4f}\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c7c0ef-2302-4782-b964-981a9ead758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model Recommendation\n",
    "best_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'class_weight': 'balanced',\n",
    "    'random_state': 42\n",
    "}\n",
    "rf_clf = RandomForestClassifier(**best_params)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705eb65-7199-47da-9ea0-8a009678aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importances\n",
    "# Although PCA-transformed features limit direct interpretability, we can still see which components were most influential.\n",
    "importances = rf_clf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Plot Feature Importances (Top 10 for readability)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.head(10), color='skyblue')\n",
    "plt.title(\"Random Forest Feature Importances (Top 10)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(recalls, precisions, label=f'Random Forest (AUPRC = {test_auprc:.4f})', color='blue')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
